#!/usr/bin/env python3
"""
Validate NOCS-based 6DoF pose estimation pipeline.

This script reads an HDF5 file generated by the synthetic data pipeline,
uses the ground truth NOCS map to estimate the 6DoF pose via PnP,
and compares it with the stored ground truth pose.

Usage:
    python validate_nocs_pose.py <path_to_hdf5_file>
"""

import argparse
import json
import sys
from pathlib import Path

import cv2
import h5py
import matplotlib.pyplot as plt
import numpy as np


def compute_rotation_error(R1, R2):
    """Compute rotation error in degrees between two rotation matrices."""
    R_diff = R1.T @ R2
    trace = np.trace(R_diff)
    # Clamp to avoid numerical issues with arccos
    trace = np.clip(trace, -1, 3)
    angle = np.arccos((trace - 1) / 2)
    return np.degrees(angle)


def compute_translation_error(t1, t2):
    """Compute Euclidean distance between two translation vectors."""
    return np.linalg.norm(t1 - t2)


def project_axes(rvec, tvec, K, axis_length=0.3):
    """
    Project 3D coordinate axes onto the image plane.

    Returns image points for origin and 3 axis endpoints (X=red, Y=green, Z=blue).
    """
    # Define 3D points: origin and 3 axis endpoints in canonical space
    axes_3d = np.float32(
        [
            [0, 0, 0],  # Origin
            [axis_length, 0, 0],  # X-axis (red)
            [0, axis_length, 0],  # Y-axis (green)
            [0, 0, axis_length],  # Z-axis (blue)
        ]
    )

    # Project to 2D
    axes_2d, _ = cv2.projectPoints(axes_3d, rvec, tvec, K, None)
    axes_2d = axes_2d.reshape(-1, 2)

    return axes_2d


def draw_axes_on_image(image, axes_2d, thickness=3):
    """Draw 3D axes on image (X=red, Y=green, Z=blue)."""
    image = image.copy()
    origin = tuple(axes_2d[0].astype(int))

    # X-axis (red)
    cv2.line(image, origin, tuple(axes_2d[1].astype(int)), (255, 0, 0), thickness)
    # Y-axis (green)
    cv2.line(image, origin, tuple(axes_2d[2].astype(int)), (0, 255, 0), thickness)
    # Z-axis (blue)
    cv2.line(image, origin, tuple(axes_2d[3].astype(int)), (0, 0, 255), thickness)

    return image


def validate_nocs_pose(hdf5_path):
    """
    Main validation function.

    Args:
        hdf5_path: Path to HDF5 file containing synthetic data

    Returns:
        Dictionary with validation results
    """
    print(f"\n{'='*70}")
    print(f"Validating NOCS-based 6DoF Pose Estimation")
    print(f"File: {hdf5_path}")
    print(f"{'='*70}\n")

    # Load HDF5 file
    with h5py.File(hdf5_path, "r") as f:
        # Load required data
        rgb_image = np.array(f["colors"])  # Shape: (H, W, 4) RGBA
        nocs_map = np.array(f["nocs"])  # Shape: (H, W, 3)
        mask = np.array(f["instance_mask"])  # Shape: (H, W)
        K_matrix = np.array(f["camera_intrinsics"])  # Shape: (3, 3)

        # Load ground truth pose
        R_gt = np.array(f["object_to_camera_rotation"])  # Shape: (3, 3)
        t_gt = np.array(f["object_to_camera_translation"])  # Shape: (3,)

        # Load metadata to get object scale
        metadata_raw = f["metadata"][()]
        if isinstance(metadata_raw, bytes):
            metadata_str = metadata_raw.decode("utf-8")
        elif isinstance(metadata_raw, np.bytes_):
            metadata_str = metadata_raw.decode("utf-8")
        else:
            metadata_str = str(metadata_raw)
        metadata = json.loads(metadata_str)
        object_scale = metadata.get("object_scale", 1.0)

        # Check for negative sample
        is_negative = f.get("is_negative", [np.array([0])])[()]
        if isinstance(is_negative, np.ndarray):
            is_negative = is_negative[0] if is_negative.size > 0 else 0

        model_name = f["model_name"][()]
        if isinstance(model_name, bytes):
            model_name = model_name.decode("utf-8")
        elif isinstance(model_name, np.bytes_):
            model_name = model_name.decode("utf-8")

    print(f"Loaded data:")
    print(f"  Model: {model_name}")
    print(f"  RGB shape: {rgb_image.shape}")
    print(f"  NOCS shape: {nocs_map.shape}")
    print(f"  Mask shape: {mask.shape}")
    print(f"  Intrinsics K:\n{K_matrix}")

    # Check if negative sample
    if is_negative:
        print(f"\n‚ö†Ô∏è  This is a NEGATIVE SAMPLE (no object present)")
        print(f"Skipping pose estimation validation.")
        return None

    # ========================================================================
    # Step 1: Extract 2D-3D correspondences from NOCS map
    # ========================================================================

    print(f"\n{'='*70}")
    print("Step 1: Extracting 2D-3D correspondences from NOCS map")
    print(f"{'='*70}")

    # Get mask pixels
    mask_indices = np.where(mask > 0)
    num_points = len(mask_indices[0])

    print(f"  Mask pixels: {num_points:,}")

    if num_points < 4:
        print(f"  ‚úó Not enough points for PnP (need at least 4)")
        return None

    # Extract 2D points (pixel coordinates)
    points_2d = np.column_stack([mask_indices[1], mask_indices[0]]).astype(np.float32)

    # Extract 3D points (NOCS coordinates) - only take first 3 channels (RGB, not alpha)
    points_3d = nocs_map[mask_indices][:, :3].astype(np.float32)

    # CRITICAL: BlenderProc NOCS maps local coords [-1,+1] to colors [0,1]
    # Convert back: [0,1] ‚Üí [-1,+1]
    points_3d_centered = 2.0 * points_3d - 1.0
    points_3d_scaled = points_3d_centered * object_scale

    print(f"  2D points shape: {points_2d.shape}")
    print(f"  3D points shape: {points_3d.shape}")
    print(f"  NOCS value range: [{points_3d.min():.3f}, {points_3d.max():.3f}]")
    print(f"  Object scale from metadata: {object_scale:.3f}")
    print(
        f"  NOCS mean: [{points_3d[:, 0].mean():.3f}, {points_3d[:, 1].mean():.3f}, {points_3d[:, 2].mean():.3f}]"
    )

    # Sanity check: NOCS should be in [0, 1] range
    if points_3d.min() < -0.1 or points_3d.max() > 1.1:
        print(f"  ‚ö†Ô∏è  Warning: NOCS values outside expected [0, 1] range!")

    # ========================================================================
    # Step 2: Estimate pose using PnP with RANSAC
    # ========================================================================

    print(f"\n{'='*70}")
    print("Step 2: Estimating pose using cv2.solvePnPRansac")
    print(f"{'='*70}")

    # Use PnP with RANSAC for robustness
    success, rvec, tvec, inliers = cv2.solvePnPRansac(
        points_3d_scaled,
        points_2d,
        K_matrix,
        None,  # No distortion
        iterationsCount=1000,
        reprojectionError=2.0,
        confidence=0.99,
        flags=cv2.SOLVEPNP_EPNP,
    )

    if not success or rvec is None:
        print(f"  ‚úó PnP failed to find a solution")
        return None

    inlier_count = len(inliers) if inliers is not None else 0
    inlier_ratio = inlier_count / num_points

    print(f"  ‚úì PnP succeeded")
    print(f"  Inliers: {inlier_count:,}/{num_points:,} ({inlier_ratio*100:.1f}%)")

    # Convert rvec to rotation matrix
    R_estimated, _ = cv2.Rodrigues(rvec)
    t_estimated = tvec.flatten()

    print(f"\n  Estimated rotation matrix:")
    print(f"    {R_estimated[0]}")
    print(f"    {R_estimated[1]}")
    print(f"    {R_estimated[2]}")
    print(f"  Estimated translation: {t_estimated}")

    print(f"\n  Ground truth rotation matrix:")
    print(f"    {R_gt[0]}")
    print(f"    {R_gt[1]}")
    print(f"    {R_gt[2]}")
    print(f"  Ground truth translation: {t_gt}")
    magnitude = np.sqrt(sum([item**2 for item in t_gt]))
    print(f"  Ground truth translation magnitude: {magnitude}")

    # ========================================================================
    # Step 3: Compare with ground truth
    # ========================================================================

    print(f"\n{'='*70}")
    print("Step 3: Comparing estimated pose with ground truth")
    print(f"{'='*70}")

    # Compute errors
    rotation_error = compute_rotation_error(R_estimated, R_gt)
    translation_error = compute_translation_error(t_estimated, t_gt)
    translation_error_percent = (translation_error / np.linalg.norm(t_gt)) * 100

    print(f"\nüìä Error Metrics:")
    print(f"  Rotation error:        {rotation_error:.4f}¬∞")
    print(f"  Translation error:     {translation_error:.4f} units")
    print(f"  Translation error:     {translation_error_percent:.2f}% of GT magnitude")
    print(f"  Inlier ratio:          {inlier_ratio*100:.1f}%")

    # Determine if pose is accurate enough
    rotation_threshold = 5.0  # degrees
    translation_threshold_percent = 5.0  # 5% of ground truth distance

    rotation_ok = rotation_error < rotation_threshold
    translation_ok = translation_error_percent < translation_threshold_percent

    print(f"\n‚úì Validation Results:")
    print(
        f"  Rotation:    {'‚úì PASS' if rotation_ok else '‚úó FAIL'} "
        + f"(threshold: {rotation_threshold}¬∞)"
    )
    print(
        f"  Translation: {'‚úì PASS' if translation_ok else '‚úó FAIL'} "
        + f"(threshold: {translation_threshold_percent}%)"
    )

    if rotation_ok and translation_ok:
        print(f"\nüéâ NOCS-based pose estimation is ACCURATE!")
        print(f"   Your data pipeline and NOCS maps are working correctly.")
    else:
        print(f"\n‚ö†Ô∏è  NOCS-based pose estimation has HIGH ERROR")
        print(f"   This may indicate issues with:")
        print(f"   - NOCS map generation")
        print(f"   - Camera intrinsics calibration")
        print(f"   - Coordinate system alignment")

    # ========================================================================
    # Step 4: Visualize results
    # ========================================================================

    print(f"\n{'='*70}")
    print("Step 4: Generating visualization")
    print(f"{'='*70}")

    # Convert rotation matrices to rvec for projection
    rvec_gt, _ = cv2.Rodrigues(R_gt)

    # Project 3D axes using both poses
    axes_estimated = project_axes(rvec, tvec, K_matrix, axis_length=0.3)
    axes_gt = project_axes(rvec_gt, t_gt.reshape(-1, 1), K_matrix, axis_length=0.3)

    # Create visualization
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))

    # RGB image
    axes[0, 0].imshow(rgb_image[:, :, :3])
    axes[0, 0].set_title("RGB Image", fontsize=12, fontweight="bold")
    axes[0, 0].axis("off")

    # Mask
    axes[0, 1].imshow(mask, cmap="gray")
    axes[0, 1].set_title("Instance Mask", fontsize=12, fontweight="bold")
    axes[0, 1].axis("off")

    # NOCS map
    axes[0, 2].imshow(nocs_map)
    axes[0, 2].set_title("NOCS Map (Ground Truth)", fontsize=12, fontweight="bold")
    axes[0, 2].axis("off")

    # Ground truth pose visualization
    img_with_gt_axes = draw_axes_on_image(rgb_image[:, :, :3], axes_gt, thickness=4)
    axes[1, 0].imshow(img_with_gt_axes)
    axes[1, 0].set_title(
        "Ground Truth Pose\n(R=X, G=Y, B=Z)", fontsize=12, fontweight="bold"
    )
    axes[1, 0].axis("off")

    # Estimated pose visualization
    img_with_est_axes = draw_axes_on_image(
        rgb_image[:, :, :3], axes_estimated, thickness=4
    )
    axes[1, 1].imshow(img_with_est_axes)
    axes[1, 1].set_title(
        "Estimated Pose (from NOCS)\n(R=X, G=Y, B=Z)", fontsize=12, fontweight="bold"
    )
    axes[1, 1].axis("off")

    # Overlay comparison
    img_overlay = rgb_image[:, :, :3].copy()
    origin_gt = tuple(axes_gt[0].astype(int))
    origin_est = tuple(axes_estimated[0].astype(int))

    # GT axes (thick, saturated colors)
    cv2.line(img_overlay, origin_gt, tuple(axes_gt[1].astype(int)), (255, 0, 0), 5)
    cv2.line(img_overlay, origin_gt, tuple(axes_gt[2].astype(int)), (0, 255, 0), 5)
    cv2.line(img_overlay, origin_gt, tuple(axes_gt[3].astype(int)), (0, 0, 255), 5)

    # Estimated axes (thin, lighter colors)
    cv2.line(
        img_overlay,
        origin_est,
        tuple(axes_estimated[1].astype(int)),
        (255, 150, 150),
        2,
    )
    cv2.line(
        img_overlay,
        origin_est,
        tuple(axes_estimated[2].astype(int)),
        (150, 255, 150),
        2,
    )
    cv2.line(
        img_overlay,
        origin_est,
        tuple(axes_estimated[3].astype(int)),
        (150, 150, 255),
        2,
    )

    axes[1, 2].imshow(img_overlay)
    axes[1, 2].set_title(
        f"Overlay (Thick=GT, Thin=Est)\n"
        + f"Rot Err: {rotation_error:.2f}¬∞, Trans Err: {translation_error_percent:.1f}%",
        fontsize=12,
        fontweight="bold",
    )
    axes[1, 2].axis("off")

    # Overall title
    status = "‚úì PASS" if (rotation_ok and translation_ok) else "‚úó FAIL"
    status_color = "green" if (rotation_ok and translation_ok) else "red"

    plt.suptitle(
        f"NOCS Pose Validation: {model_name}\nStatus: {status}",
        fontsize=16,
        fontweight="bold",
        color=status_color,
    )
    plt.tight_layout()

    # Save figure
    output_path = Path(hdf5_path).parent / f"validation_{Path(hdf5_path).stem}.png"
    plt.savefig(output_path, dpi=150, bbox_inches="tight")
    print(f"  ‚úì Saved visualization to: {output_path}")

    plt.show()

    # ========================================================================
    # Return results
    # ========================================================================

    return {
        "success": True,
        "rotation_error_deg": rotation_error,
        "translation_error": translation_error,
        "translation_error_percent": translation_error_percent,
        "rotation_pass": rotation_ok,
        "translation_pass": translation_ok,
        "inlier_ratio": inlier_ratio,
        "num_correspondences": num_points,
    }


def main():
    parser = argparse.ArgumentParser(
        description="Validate NOCS-based 6DoF pose estimation from HDF5 file",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Example usage:
    python validate_nocs_pose.py /path/to/output/0.hdf5
    python validate_nocs_pose.py /path/to/output/123.hdf5
        """,
    )
    parser.add_argument(
        "hdf5_file", type=str, help="Path to HDF5 file containing synthetic data"
    )

    args = parser.parse_args()

    hdf5_path = Path(args.hdf5_file)

    # Check file exists
    if not hdf5_path.exists():
        print(f"‚ùå Error: File not found: {hdf5_path}")
        sys.exit(1)

    # Run validation
    result = validate_nocs_pose(hdf5_path)

    if result is None:
        print(f"\n‚ö†Ô∏è  Validation could not be completed")
        sys.exit(1)

    # Print summary
    print(f"\n{'='*70}")
    print("üìã SUMMARY")
    print(f"{'='*70}")
    print(f"Rotation error:     {result['rotation_error_deg']:.4f}¬∞")
    print(
        f"Translation error:  {result['translation_error']:.4f} units ({result['translation_error_percent']:.2f}%)"
    )
    print(f"Inlier ratio:       {result['inlier_ratio']*100:.1f}%")
    print(f"Correspondences:    {result['num_correspondences']:,}")

    overall_pass = result["rotation_pass"] and result["translation_pass"]
    print(f"\nOverall Status:     {'‚úì PASS' if overall_pass else '‚úó FAIL'}")
    print(f"{'='*70}\n")

    if overall_pass:
        print("‚úÖ Your NOCS pipeline is ready for training!")
    else:
        print("‚ö†Ô∏è  Please investigate the errors before proceeding to training.")

    # Exit code
    sys.exit(0 if overall_pass else 1)


if __name__ == "__main__":
    main()
